{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862696f8-ae14-4f37-846a-43bdd8eb6963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "\n",
    "def create_df(test,pred):\n",
    "    \n",
    "    df=pd.DataFrame({\n",
    "                  'true':test,\n",
    "                  'pred':pred, #predicted value, hopefully close to \"true\"\n",
    "                  'log_ret':np.log(test/test.shift(1)), #today over yesterday return\n",
    "                  'pred_ret': np.log(pred/test.shift(1)),\n",
    "                 })\n",
    "    \n",
    "    df['cum_ret']=np.exp(df.log_ret.cumsum())\n",
    "    \n",
    "    df['pos']=np.sign(df.pred_ret).shift(0)\n",
    "    daily_stg_log_ret=df.pos*df.log_ret.shift(0)\n",
    "    df['stg_ret']=np.exp(daily_stg_log_ret.cumsum())\n",
    "    #also equals #df['stg_ret']=np.exp((np.sign(df.pred_ret)*df.log_ret).cumsum())\n",
    "    \n",
    "    #shift the pred columns -1 to get the expected values for tomorrow\n",
    "    #shift the pos by -1 to get the position to hold tomorrow = the actions to perform today\n",
    "    \n",
    "    return df\n",
    "\n",
    "########################################################\n",
    "\n",
    "def log_ret(prices):\n",
    "    log_ret=np.log(prices/prices.shift(1))\n",
    "    return log_ret\n",
    "\n",
    "def cum_ret(prices):\n",
    "    cum_ret=np.exp(log_ret(prices).cumsum())\n",
    "    return cum_ret\n",
    "\n",
    "def stg_ret(true_log_ret,pred_log_ret, short=True):\n",
    "    \n",
    "    cum_ret = np.exp(true_log_ret.cumsum())\n",
    "    pos     = np.sign(pred_log_ret) #shorting allowed\n",
    "    if short==False:\n",
    "        pos     = pos.replace(-1,0)\n",
    "    daily_stg_log_ret= pos * true_log_ret\n",
    "    stg_ret =np.exp(daily_stg_log_ret.cumsum())\n",
    "    \n",
    "    return stg_ret\n",
    "    \n",
    "########################################################\n",
    "\n",
    "def get_prices(ticker,start,end):\n",
    "    data_raw=yf.Ticker(ticker).history(start=start, end=end).Close\n",
    "    data_raw.index=pd.to_datetime(data_raw.index.date)\n",
    "    return data_raw\n",
    "\n",
    "\n",
    "def split_train_test(data_raw,test_start):\n",
    "    train=data_raw.loc[:test_start].iloc[:-1]\n",
    "    test= data_raw.loc[test_start:]\n",
    "    return train,test\n",
    "\n",
    "\n",
    "def make_xy(data,use_steps,steps_ahead):\n",
    "        #batch_size=len(aapl)-use_steps-steps_ahead+1\n",
    "        batch_size=data.shape[0]-use_steps\n",
    "    \n",
    "        X=np.zeros((batch_size,use_steps,1))\n",
    "        y=np.zeros((batch_size,use_steps,steps_ahead))\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            for step in range(use_steps):\n",
    "                X_instance=data[i:i+use_steps]\n",
    "               #y_instance=data[i+use_steps:i+use_steps+steps_ahead]\n",
    "                y_instance=data[i+step+1:i+1+step+steps_ahead].reshape(-1)\n",
    "            \n",
    "                X[i,:,:]=X_instance\n",
    "                y[i,step,:]=y_instance\n",
    "                y_1d=y[:,-1,0]\n",
    "        return X,y_1d\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "\n",
    "def preprocess_train_test(train,test,use_steps,steps_ahead):\n",
    "    train_sc=scaler.fit_transform(train.values.reshape(-1,1))\n",
    "    test_sc =scaler.transform(test.values.reshape(-1,1))\n",
    "        \n",
    "    X_train, y_train =  make_xy(train_sc,use_steps,steps_ahead)\n",
    "    X_test,  y_test  =  make_xy(test_sc,use_steps,steps_ahead)\n",
    "    return X_train,y_train, X_test,y_test\n",
    "\n",
    "\n",
    "\n",
    "########################################################\n",
    "########################################################\n",
    "\n",
    "\n",
    "def get_paths(name):\n",
    "    fits_path = os.path.join('fits','{}'.format(name))\n",
    "    cp_path = os.path.join(fits_path, 'checkpoints')\n",
    "    sm_path = os.path.join(fits_path, 'saved_models')\n",
    "    return fits_path, cp_path, sm_path\n",
    "\n",
    "def check_make_dir(name):\n",
    "    if not os.path.isdir('fits'):\n",
    "        os.mkdir('fits')\n",
    "        \n",
    "    fits_path,cp_path,sm_path = get_paths(name)\n",
    "    if not os.path.isdir(fits_path):\n",
    "        os.mkdir(fits_path)\n",
    "        os.mkdir(cp_path)\n",
    "        os.mkdir(sm_path)\n",
    "    return\n",
    "        \n",
    "def fit_save(name, X_train,y_train,X_test,y_test,model,\n",
    "             #checkpoints, optimizer, \n",
    "             epochs, patience=0):\n",
    "    check_make_dir(name)\n",
    "    fits_path, cp_path, sm_path = get_paths(name)\n",
    "    checkpoint_path  =os.path.join(cp_path,'{}_{}_cp.keras'.format(name,model.name))\n",
    "    saved_model_path =os.path.join(sm_path,'{}_{}.keras'.format(name,model.name))\n",
    "\n",
    "    early_stopping=keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                 patience=patience,\n",
    "                                                 restore_best_weights=True)\n",
    "   \n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                    monitor=\"val_loss\", mode=\"min\", \n",
    "                    save_best_only=True, verbose=1)\n",
    "    \n",
    "    optimizer=keras.optimizers.RMSprop()\n",
    "    model.compile(loss='mean_squared_error',optimizer=optimizer)\n",
    "    result=model.fit(X_train,y_train,\n",
    "                     validation_data=(X_test,y_test),\n",
    "                     epochs=epochs,\n",
    "                     callbacks=[\n",
    "                         checkpoint,\n",
    "                         early_stopping\n",
    "                                ])\n",
    "\n",
    "    model.load_weights(checkpoint_path)\n",
    "    model.save(saved_model_path)\n",
    "    \n",
    "########################################################\n",
    "########################################################\n",
    "\n",
    "def create_pred(model,X_test):  ###references global variable (scaler)\n",
    "    model_pred=model.predict(X_test)\n",
    "    model_pred=scaler.inverse_transform(model_pred).reshape(-1)\n",
    "    model_pred=pd.Series(model_pred,index=test.index[use_steps:])\n",
    "    return model_pred\n",
    "\n",
    "\n",
    "\n",
    "#Load saved models\n",
    "def load_models(fit_name):\n",
    "    sm_path=get_paths(fit_name)[2]\n",
    "    files=os.listdir(sm_path)\n",
    "    filenames=[filename for filename in files if filename[-6:]=='.keras']\n",
    "    models=dict()\n",
    "    for filename in filenames:\n",
    "        model_path=os.path.join(sm_path,filename)\n",
    "        models[filename[:-6]]=keras.saving.load_model(model_path)\n",
    "    return models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prices_from_logrets(preds,test_price):\n",
    "    logrets = preds\n",
    "    cumrets = np.exp(logrets.cumsum())  #cumulative returns are normalized prices\n",
    "    cumrets = cumrets/cumrets.iloc[0,0] #make it start from 1 (we took returns before splitting train and test)\n",
    "    prices  = test_price.iloc[0]*cumrets\n",
    "   # prices.iloc[:,0] = test_price\n",
    "    return prices\n",
    "\n",
    "\n",
    "\n",
    "def get_rps(test_price,preds,kind):\n",
    "\n",
    "    preds=preds.dropna() #gets rid of the first test_price data up to use_steps index (all plots below will start from the same index)\n",
    "    \n",
    "    if kind=='prices':\n",
    "        prices = preds\n",
    "        logrets = log_ret(prices)\n",
    "        cumrets = cum_ret(prices)\n",
    "        \n",
    "    if kind=='returns':\n",
    "        logrets = preds\n",
    "        prices  = prices_from_logrets(preds,test_price)\n",
    "        cumrets = np.exp(logrets.cumsum())\n",
    "    \n",
    "    strats  = cumrets.copy()\n",
    "    \n",
    "    #strats.iloc[:,0]=cumrets.iloc[:,0]/cumrets.iloc[use_steps,0] #normalized from start of trading actions; comment this line to start from test set start\n",
    "                                                                  #depends if log_ret is dropping nan or not\n",
    "    for col in strats.columns[1:]:\n",
    "        strats[col]=stg_ret(logrets.iloc[:,0],logrets[col])\n",
    "\n",
    "    return logrets,prices,strats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print plots given data from rps function\n",
    "def get_plots(rps_output):\n",
    "    fig,ax=plt.subplots(nrows=3)\n",
    "    plt.subplots_adjust(top = 2, bottom=0, left=0, right=2,hspace=0.25, wspace=0)\n",
    "    for i,df in enumerate(rps_output):\n",
    "        df.plot(ax=ax[i],lw=1, alpha=1)\n",
    "    ax[2].axhline(y=1, c='r',lw=0.5,alpha=0.5)\n",
    "    test_start_idx=rps_output[0].index[use_steps]\n",
    "    #ax[2].axvline(x=test_start_idx, c='k', lw=0.5, alpha=0.5)\n",
    "    #plt.fill_between(x=test_start_idx, y1=0,y2=1)\n",
    "    ax[0].set_title('Returns')\n",
    "    ax[1].set_title('Prices')\n",
    "    ax[2].set_title('Strategies')\n",
    "    \n",
    "    print(rps_output[-1].iloc[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0ea37cd-6bb6-426e-840b-6cd08edaf385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6d9f8-fa38-46bd-9cfc-bdc02b7ba2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##old\n",
    "\n",
    "def make_preds(models,test,X_test): #argument is a dictionary modelname:model\n",
    "    \n",
    "    preds=dict()\n",
    "    preds['stock']=test\n",
    "    for modelname,model in models.items():\n",
    "        pred=create_pred(model, X_test)\n",
    "        preds[modelname]=pred\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d15e0-8750-4ba1-909e-548fefc39390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a433da7-15bb-4d7c-aef5-6fc1471b2851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ee998-b2a9-46c6-9a25-a1b463460567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a5d1f-411a-41f8-9806-a4e35afd64e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
